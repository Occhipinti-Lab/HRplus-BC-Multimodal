{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7LQPs4fTWhF"
      },
      "source": [
        "# **Introduction**\n",
        "\n",
        "This notebook processes single-cell RNA sequencing data from the GSE300475 dataset to prepare it for downstream multimodal analysis. It covers downloading and extracting the raw data files, loading and annotating the gene expression matrix with patient and response metadata, and performing normalization, log-transformation, and selection of highly variable genes to reduce noise and focus on informative features. Key preprocessing steps are visualized, including gene variability and dimensionality reduction using PCA, both before and after filtering. Finally, the processed gene expression data is exported along with cell-level metadata to support integration with other data modalities and enable machine learning modeling of treatment response in breast cancer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqAlrUCUDX6R"
      },
      "source": [
        "**Step 1**: *Reset Google Drive Mount in Colab*\n",
        "\n",
        "* This step ensures that any previous Google Drive mount is safely removed before starting fresh.\n",
        "* First, the code tries to unmount Google Drive using `drive.flush_and_unmount()`. If Drive isn’t mounted yet, it catches and prints the exception.\n",
        "* Then it checks if the `/content/drive` folder still exists, and removes it using `shutil.rmtree()`. This clears any leftover mount point data.\n",
        "* This is helpful when switching accounts, resolving permission errors, or restarting workflows cleanly.\n",
        "* After this step, you're ready to freshly mount Google Drive again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0uHrNY0sdMV",
        "outputId": "3fe98ea2-b74b-4073-911f-4c9f9d28405f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Cleaned /content/drive. Now you can mount again.\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import os\n",
        "import scanpy as sc\n",
        "from google.colab import drive\n",
        "import tarfile\n",
        "\n",
        "# Try unmount if already mounted\n",
        "try:\n",
        "    drive.flush_and_unmount()\n",
        "except Exception as e:\n",
        "    print(\"Unmount failed or not mounted yet:\", e)\n",
        "\n",
        "# Now remove the folder manually if it still exists\n",
        "if os.path.exists(\"/content/drive\"):\n",
        "    shutil.rmtree(\"/content/drive\", ignore_errors=True)\n",
        "\n",
        "print(\"Cleaned /content/drive. Now you can mount again.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddqXRqPlEFiA"
      },
      "source": [
        "**Step 2**: *Mount Google Drive*\n",
        "\n",
        "* After cleaning up any previous mount (Step 1), we now freshly mount Google Drive into the Colab environment.\n",
        "* The method `drive.mount('/content/drive')` prompts you to authenticate using your Google account.\n",
        "* Once authenticated, it creates a virtual mount point at `/content/drive` where all your Drive files can be accessed just like a local directory.\n",
        "* This is essential for reading datasets, saving outputs, or loading pre-existing files from Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWU5B_yusuzE",
        "outputId": "db20aea7-2df2-4450-c19c-038b90165cf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et1RW7JyEn2z"
      },
      "source": [
        "**Step 3**: *Download and Extract TCR Data Archive from GEO*\n",
        "\n",
        "* This step handles the download and extraction of the **TCR-seq dataset (GSE300475)** from the NCBI GEO repository.\n",
        "* We **force re-mount** Google Drive (`force_remount=True`) to ensure a clean mount in case of residual connections or folder conflicts.\n",
        "* The `.tar` archive is then downloaded directly into your Google Drive under `/MyDrive`.\n",
        "* We use Python's `tarfile` module to extract the contents to a new folder, `/MyDrive/GSE300475_extracted`, making all files accessible for downstream processing.\n",
        "\n",
        "**File downloaded**:\n",
        "`GSE300475_RAW.tar` (566 MB)\n",
        "\n",
        "**Extraction folder**:\n",
        "`/content/drive/MyDrive/GSE300475_extracted`\n",
        "\n",
        "**Expected Output Summary**:\n",
        "\n",
        "* `Mounted at /content/drive`\n",
        "* Confirmation of successful download via `wget`\n",
        "* `Extraction complete.` after untarring the contents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "My2jFIjeSnIw",
        "outputId": "833586a9-ff6e-4691-c4d3-04dae9041ab8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "--2025-10-04 18:33:38--  https://ftp.ncbi.nlm.nih.gov/geo/series/GSE300nnn/GSE300475/suppl/GSE300475_RAW.tar\n",
            "Resolving ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)... 130.14.250.11, 130.14.250.12, 130.14.250.13, ...\n",
            "Connecting to ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)|130.14.250.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 592977920 (566M) [application/x-tar]\n",
            "Saving to: ‘/content/drive/MyDrive/Data/rawdata/GSE300475_RAW.tar’\n",
            "\n",
            "/content/drive/MyDr 100%[===================>] 565.51M  31.6MB/s    in 20s     \n",
            "\n",
            "2025-10-04 18:33:59 (27.7 MB/s) - ‘/content/drive/MyDrive/Data/rawdata/GSE300475_RAW.tar’ saved [592977920/592977920]\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2095760645.py:15: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "  tar.extractall(path=extract_path)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extraction complete.\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive (force remount to avoid folder conflict)\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Change this path to where you want to store it\n",
        "download_path = '/content/drive/MyDrive/Data/rawdata/GSE300475_RAW.tar'\n",
        "\n",
        "# Download the TAR archive\n",
        "!wget -O \"$download_path\" \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE300nnn/GSE300475/suppl/GSE300475_RAW.tar\"\n",
        "\n",
        "# Extract it\n",
        "extract_path = '/content/drive/MyDrive/Data/rawdata'\n",
        "with tarfile.open(download_path, 'r') as tar:\n",
        "    tar.extractall(path=extract_path)\n",
        "\n",
        "print(\"Extraction complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7k7SgfkFS9o"
      },
      "source": [
        "**Step 4**: *Install Scanpy Library*\n",
        "\n",
        "* This step installs the `scanpy` package, which is a comprehensive Python library for analyzing single-cell RNA-seq data.\n",
        "\n",
        "* It provides tools for data preprocessing, dimensionality reduction, clustering, visualization, and differential expression analysis.\n",
        "\n",
        "* Installation is done using `pip` and will work only within the current Colab session unless re-installed after a restart.\n",
        "\n",
        "* Installed package: `scanpy`\n",
        "\n",
        "* Automatically includes key dependencies such as `anndata`, `numpy`, `pandas`, `scikit-learn`, `matplotlib`, and `scipy`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UECj6II1FnAK"
      },
      "source": [
        "**Step 5**: *Load and Combine Single-Cell Gene Expression Data from Multiple Samples*\n",
        "\n",
        "* The extracted directory containing 10X Genomics formatted data is scanned to identify all samples by detecting barcode files (`barcodes.tsv.gz`).\n",
        "\n",
        "* Sample prefixes are automatically extracted from filenames for batch loading.\n",
        "\n",
        "* Each sample is loaded individually using Scanpy’s `read_10x_mtx` function with gene IDs as variable names.\n",
        "\n",
        "* A new observation column `sample_id` is added to each AnnData object to keep track of the sample origin.\n",
        "\n",
        "* All sample AnnData objects are concatenated into a single combined AnnData object for unified downstream analysis.\n",
        "\n",
        "* A warning about duplicate observation (cell) names appears because different samples may have overlapping barcode IDs; this can be resolved later if needed by calling `.obs_names_make_unique()`.\n",
        "\n",
        "* The combined dataset contains approximately 100,067 cells and 36,601 genes.\n",
        "\n",
        "* The final combined AnnData object is saved to Google Drive in `.h5ad` format for persistent storage and future use.\n",
        "\n",
        "* Input path: `/content/drive/MyDrive/GSE300475_extracted`\n",
        "\n",
        "* Output file: `/content/drive/MyDrive/MultimodalCSVs/gene_expression_combined_raw.h5ad`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsQ8drOMtU_x",
        "outputId": "adee5f00-8e7b-4298-c3f8-1cefb6a62b3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading: GSM9061665_S1\n",
            "Loading: GSM9061666_S2\n",
            "Loading: GSM9061667_S3\n",
            "Loading: GSM9061668_S4\n",
            "Loading: GSM9061669_S5\n",
            "Loading: GSM9061670_S6\n",
            "Loading: GSM9061671_S7\n",
            "Loading: GSM9061672_S8\n",
            "Loading: GSM9061673_S9\n",
            "Loading: GSM9061674_S10\n",
            "Loading: GSM9061675_S11\n",
            "Concatenating samples...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/anndata/_core/anndata.py:1791: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"obs\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined shape: (100067, 36601)\n",
            "Saving combined AnnData to disk...\n",
            "Saved to: /content/drive/MyDrive/Data/rawdata/gene_expression_combined_raw.h5ad\n"
          ]
        }
      ],
      "source": [
        "# Path to the extracted directory\n",
        "extract_path = '/content/drive/MyDrive/Data/rawdata'\n",
        "\n",
        "# List all barcodes files to detect the sample prefixes automatically\n",
        "sample_prefixes = sorted([\n",
        "    f.split('_')[0] + \"_\" + f.split('_')[1]\n",
        "    for f in os.listdir(extract_path)\n",
        "    if f.endswith('barcodes.tsv.gz')\n",
        "])\n",
        "\n",
        "# Load each sample individually\n",
        "adatas = []\n",
        "\n",
        "for sample in sample_prefixes:\n",
        "    print(f\"Loading: {sample}\")\n",
        "    adata = sc.read_10x_mtx(\n",
        "        extract_path,\n",
        "        var_names='gene_ids',\n",
        "        prefix=sample + \"_\",\n",
        "        cache=True\n",
        "    )\n",
        "    adata.obs['sample_id'] = sample\n",
        "    adatas.append(adata)\n",
        "\n",
        "# Concatenate all AnnData objects\n",
        "print(\"Concatenating samples...\")\n",
        "combined_adata = sc.concat(adatas, label='sample_id', keys=sample_prefixes)\n",
        "\n",
        "print(f\"Combined shape: {combined_adata.shape}\")\n",
        "print(\"Saving combined AnnData to disk...\")\n",
        "\n",
        "# Save the combined AnnData to Google Drive\n",
        "save_path = '/content/drive/MyDrive/Data/rawdata/gene_expression_combined_raw.h5ad'\n",
        "os.makedirs('/content/drive/MyDrive/Data/rawdata', exist_ok=True)\n",
        "combined_adata.write(save_path)\n",
        "\n",
        "print(f\"Saved to: {save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1w8kU_VGCAr"
      },
      "source": [
        "**Step 6**: *Annotate Cells with Patient ID and Treatment Response Labels*\n",
        "\n",
        "* The previously saved combined AnnData object is loaded from disk.\n",
        "\n",
        "* A mapping dictionary links the original sample IDs (`sample_id`) to patient IDs (`patient_id`), standardizing sample names to meaningful patient codes (e.g., `\"GSM9061665_S1\"` → `\"PT1\"`).\n",
        "\n",
        "* Known responder and non-responder patient sets are defined based on clinical metadata.\n",
        "\n",
        "* Each cell is annotated with its corresponding patient ID using the mapping.\n",
        "\n",
        "* A new categorical column `response` is added, classifying cells as `\"Responder\"`, `\"Non-responder\"`, or `\"Unknown\"` depending on patient membership in responder/non-responder groups.\n",
        "\n",
        "* Cells with unknown response status (e.g., samples labeled `\"Week1\"` or `\"Week3\"`) are filtered out to focus the analysis on well-defined response groups.\n",
        "\n",
        "* The filtered and annotated AnnData object is saved back to Google Drive.\n",
        "\n",
        "* The final dataset contains 58,177 cells and 36,601 genes, with about 19,201 responder cells and 38,976 non-responder cells.\n",
        "\n",
        "* Input file: `/content/drive/MyDrive/MultimodalCSVs/gene_expression_combined_raw.h5ad`\n",
        "\n",
        "* Output file: `/content/drive/MyDrive/MultimodalCSVs/gene_expression_annotated.h5ad`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "4DOilcBjo7Sx",
        "outputId": "80b96c4e-40ce-4432-8801-5c9564240f16"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/anndata/_core/anndata.py:1791: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"obs\")\n",
            "/usr/local/lib/python3.12/dist-packages/anndata/_core/anndata.py:1791: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"obs\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Annotated AnnData saved to:\n",
            "/content/drive/MyDrive/Data/rawdata/gene_expression_annotated.h5ad\n",
            "Final shape: (58177, 36601)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Non-responder</th>\n",
              "      <td>38976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Responder</th>\n",
              "      <td>19201</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "response\n",
              "Non-responder    38976\n",
              "Responder        19201\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your saved raw data\n",
        "adata = sc.read_h5ad(\"/content/drive/MyDrive/Data/rawdata/gene_expression_combined_raw.h5ad\")\n",
        "\n",
        "# Mapping from GSM ID to patient ID\n",
        "gsm_to_patient = {\n",
        "    \"GSM9061665_S1\": \"PT1\",\n",
        "    \"GSM9061666_S2\": \"PT6\",\n",
        "    \"GSM9061667_S3\": \"PT7\",\n",
        "    \"GSM9061668_S4\": \"PT13\",\n",
        "    \"GSM9061669_S5\": \"PT15\",\n",
        "    \"GSM9061670_S6\": \"Week3\",\n",
        "    \"GSM9061671_S7\": \"Week3_addition\",\n",
        "    \"GSM9061672_S8\": \"PT15_add\",\n",
        "    \"GSM9061673_S9\": \"PT11\",\n",
        "    \"GSM9061674_S10\": \"PT5\",\n",
        "    \"GSM9061675_S11\": \"Week1\"\n",
        "}\n",
        "\n",
        "# Known responders/non-responders\n",
        "responder_pts = {\"PT1\", \"PT7\", \"PT15\"}\n",
        "non_responder_pts = {\"PT5\", \"PT6\", \"PT11\", \"PT13\"}\n",
        "\n",
        "# Add patient_id to obs\n",
        "adata.obs['patient_id'] = adata.obs['sample_id'].map(gsm_to_patient)\n",
        "\n",
        "# Add response label\n",
        "def classify_response(pid):\n",
        "    if pid in responder_pts:\n",
        "        return \"Responder\"\n",
        "    elif pid in non_responder_pts:\n",
        "        return \"Non-responder\"\n",
        "    else:\n",
        "        return \"Unknown\"\n",
        "\n",
        "adata.obs['response'] = adata.obs['patient_id'].map(classify_response)\n",
        "\n",
        "# Remove cells with unknown response\n",
        "adata = adata[adata.obs['response'] != \"Unknown\"].copy()\n",
        "\n",
        "# Save the annotated file\n",
        "annotated_path = \"/content/drive/MyDrive/Data/rawdata/gene_expression_annotated.h5ad\"\n",
        "adata.write(annotated_path)\n",
        "print(f\"Annotated AnnData saved to:\\n{annotated_path}\")\n",
        "print(f\"Final shape: {adata.shape}\")\n",
        "adata.obs['response'].value_counts()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
