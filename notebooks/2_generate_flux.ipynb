{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "535ec53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Added to sys.path: /home/sadegh/python_projects/HRplus-BC-Multimodal\n",
      "‚úÖ Environment initialized.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from tqdm.auto import tqdm\n",
    "from anndata import AnnData\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "import cobra\n",
    "\n",
    "project_root = Path(os.getcwd()).parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "print(\"‚úÖ Added to sys.path:\", project_root)\n",
    "\n",
    "from scripts.utils_scFBApy import scFBApy, repairNeg\n",
    "\n",
    "print(\"‚úÖ Environment initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6db5399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è All warnings suppressed for cleaner output.\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"ChainedAssignmentError\")\n",
    "\n",
    "print(\"‚öôÔ∏è All warnings suppressed for cleaner output.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fde71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ PATHS\n",
      "---------------------------------\n",
      "Input data:  /home/sadegh/python_projects/HRplus-BC-Multimodal/dataset/transcriptomic_hvg.csv\n",
      "Metadata:    /home/sadegh/python_projects/HRplus-BC-Multimodal/dataset/metadata.csv\n",
      "Model:       /home/sadegh/python_projects/HRplus-BC-Multimodal/models/model.xml\n",
      "Output dir:  /home/sadegh/python_projects/HRplus-BC-Multimodal/flux_batch\n",
      "Final file:  /home/sadegh/python_projects/HRplus-BC-Multimodal/dataset/fluxomics.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set directories of files\n",
    "base_dir = Path().resolve().parent\n",
    "\n",
    "input_file = base_dir / \"dataset/transcriptomic_hvg.csv\"\n",
    "meta_data = base_dir / \"dataset/metadata.csv\"\n",
    "model_file = base_dir / \"models/model.xml\"\n",
    "output_dir = base_dir / \"flux_batch\"\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "final_output = base_dir / \"dataset/fluxomics.csv\"\n",
    "\n",
    "print(f\"\"\"\n",
    "üìÇ PATHS\n",
    "---------------------------------\n",
    "Input data:  {input_file}\n",
    "Metadata:    {meta_data}\n",
    "Model:       {model_file}\n",
    "Output dir:  {output_dir}\n",
    "Final file:  {final_output}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138433cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Transcriptomic Data\n",
    "print(\"üì• Loading transcriptomics data...\")\n",
    "trans = pd.read_csv(input_file, index_col=0)\n",
    "print(f\"Expression matrix shape: {trans.shape}\")\n",
    "trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc79f1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Cobra model\n",
    "print(\"üß¨ Loading COBRA metabolic model...\")\n",
    "model = cobra.io.read_sbml_model(model_file)\n",
    "model_genes = [g.id for g in model.genes]\n",
    "print(f\"Model loaded: {len(model_genes)} genes, {len(model.reactions)} reactions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb56f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to Model Genes and Build AnnData\n",
    "overlap_genes = [g for g in trans.columns if g in model_genes]\n",
    "expr_filtered = trans[overlap_genes]\n",
    "adata_expr = AnnData(expr_filtered)\n",
    "\n",
    "print(f\"‚úÖ Overlapping genes with model: {len(overlap_genes)}\")\n",
    "print(f\"AnnData object: {adata_expr.shape}\")\n",
    "adata_expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abc6475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Parameters\n",
    "batch_size = 100\n",
    "objective = \"Biomass\"\n",
    "n_cells = adata_expr.shape[0]\n",
    "n_batches = (n_cells + batch_size - 1) // batch_size\n",
    "\n",
    "print(f\"Total cells: {n_cells}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Total batches: {n_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ec3b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run scFBApy on each batch\n",
    "def run_batch(batch_idx):\n",
    "    \"\"\"Run scFBApy flux computation on a batch of cells\"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import warnings\n",
    "    from scripts.utils_scFBApy import scFBApy\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "    warnings.filterwarnings(\"ignore\", message=\"ChainedAssignmentError\")\n",
    "\n",
    "    start = batch_idx * batch_size\n",
    "    end = min((batch_idx + 1) * batch_size, n_cells)\n",
    "    batch_file = output_dir / f\"flux_batch_{batch_idx}.csv\"\n",
    "\n",
    "    if batch_file.exists():\n",
    "        return f\"üü¢ Skipped batch {batch_idx+1} (already done)\"\n",
    "\n",
    "    adata_batch = adata_expr[start:end, :].copy()\n",
    "\n",
    "    try:\n",
    "        adata_flux_batch = scFBApy(\n",
    "            model_orig=model,\n",
    "            adata=adata_batch,\n",
    "            objective=objective,\n",
    "            cooperation=True,\n",
    "            compute_fva=True,\n",
    "            npop_fva=5,\n",
    "            eps=0.001,\n",
    "            type_ras_normalization=\"max\",\n",
    "            and_expression=np.nanmin,\n",
    "            or_expression=np.nansum,\n",
    "            fraction_of_optimum=0,\n",
    "            processes=1,\n",
    "            round_c=10\n",
    "        )\n",
    "\n",
    "        flux_df = pd.DataFrame(\n",
    "            adata_flux_batch.X,\n",
    "            index=adata_flux_batch.obs.index,\n",
    "            columns=adata_flux_batch.var.index\n",
    "        )\n",
    "        flux_df.to_csv(batch_file)\n",
    "        return f\"‚úÖ Finished batch {batch_idx+1}/{n_batches}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"‚ö†Ô∏è Error in batch {batch_idx}: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71d3a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Fluxomics data from Transcriptomics\n",
    "print(\"üöÄ Starting parallel flux computation...\")\n",
    "start_time = time.time()\n",
    "\n",
    "with Pool(processes=8) as pool:  # adjust CPU count as needed\n",
    "    results = list(tqdm(pool.imap(run_batch, range(n_batches)), total=n_batches))\n",
    "\n",
    "for r in results:\n",
    "    print(r)\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Total runtime: {(time.time() - start_time)/60:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d94580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine All Batch Files\n",
    "print(\"üì¶ Combining all batch files...\")\n",
    "batch_files = sorted(output_dir.glob(\"flux_batch_*.csv\"))\n",
    "combined_flux = pd.concat([pd.read_csv(f, index_col=0) for f in batch_files])\n",
    "print(f\"Combined flux shape: {combined_flux.shape}\")\n",
    "combined_flux.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebb76bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Metadata and Save Final File\n",
    "meta_df = pd.read_csv(meta_data, index_col=0)\n",
    "combined_flux.index = meta_df.index.values[: combined_flux.shape[0]]\n",
    "combined_flux[\"response\"] = meta_df[\"response\"].values[: combined_flux.shape[0]]\n",
    "\n",
    "combined_flux.to_csv(final_output, index=True)\n",
    "print(f\"üíæ Final fluxomics file saved to: {final_output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
